<p align="center">
  <img src="docs/banner.png" alt="Nano Banana Banner" width="100%"/>
</p>

<h1 align="center">ğŸŒ Nano Banana</h1>

<p align="center">
  <b>AI-Powered Multimodal Fashion Search Assistant</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/Gemini-8E75B2?style=for-the-badge&logo=google&logoColor=white" alt="Gemini"/>
  <img src="https://img.shields.io/badge/Qdrant-DC382D?style=for-the-badge&logo=qdrant&logoColor=white" alt="Qdrant"/>
  <img src="https://img.shields.io/badge/SigLIP-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="SigLIP"/>
</p>

<p align="center">
  Search fashion products using <b>text</b>, <b>images</b>, or <b>both</b> â€” powered by semantic vector search and conversational AI.
</p>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Semantic Search** | Find products by meaning, not just keywords â€” powered by SigLIP embeddings |
| ğŸ–¼ï¸ **Image Search** | Upload a photo and find visually similar products instantly |
| ğŸ§  **AI Chat Assistant** | Conversational interface with intent detection (chat vs. search) |
| ğŸŒ **Bilingual Support** | Seamless Arabic â†” English â€” queries are auto-translated for optimal search |
| ğŸ’° **Smart Filtering** | Price range filters extracted automatically from natural language |
| ğŸ—ƒï¸ **Product Grouping** | Results merge image + text data per product for rich, complete cards |
| âš¡ **Real-time UI** | Modern chat interface with image upload, suggestion chips, and smooth UX |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Chat UI (Browser)                    â”‚
â”‚            HTML / CSS / JS  â€¢  Jinja2 Templates         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚  HTTP (REST)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend                        â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Intent   â”‚  â”‚ Param        â”‚  â”‚ Response           â”‚  â”‚
â”‚  â”‚ Classify â”‚â”€â”€â”‚ Extraction   â”‚â”€â”€â”‚ Generation         â”‚  â”‚
â”‚  â”‚ (Gemini) â”‚  â”‚ (Gemini)     â”‚  â”‚ (Gemini)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        Semantic Search Engine                      â”‚  â”‚
â”‚  â”‚  SigLIP Embeddings  +  Qdrant Vector DB            â”‚  â”‚
â”‚  â”‚  (Text & Image vectors in shared latent space)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

1. **User sends a query** â€” text, image, or both
2. **Intent Classification** â€” Gemini determines if the user wants to *search* or *chat*
3. **Parameter Extraction** â€” Gemini extracts keywords, category, color, fit, and price constraints from the query (Arabic is translated to English for embedding)
4. **Embedding Generation** â€” SigLIP generates a vector for the query (text or image)
5. **Vector Search** â€” Qdrant finds the most similar products using cosine similarity + metadata filters
6. **Product Grouping** â€” Results are grouped by product folder, merging image and text data
7. **Natural Response** â€” Gemini generates a friendly, human-like response presenting the results

---

## ğŸ“ Project Structure

```
nano-banana/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py                 # FastAPI application & endpoints
â”‚   â”œâ”€â”€ main.py                # CLI interface for search
â”‚   â”œâ”€â”€ config.py              # Environment config (API keys, DB settings)
â”‚   â”œâ”€â”€ llm_utils.py           # Gemini LLM integrations (intent, extraction, response)
â”‚   â”œâ”€â”€ model_utils.py         # SigLIP model loading & embedding generation
â”‚   â”œâ”€â”€ search_utils.py        # Qdrant vector search with filtering & grouping
â”‚   â”œâ”€â”€ product_ingestion.py   # Batch product data ingestion pipeline
â”‚   â”œâ”€â”€ system_prompt.txt      # AI assistant persona & behavior rules
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/style.css      # UI styles
â”‚   â”‚   â””â”€â”€ js/main.js         # Frontend logic
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html         # Chat UI template
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_search_flow.py    # End-to-end search flow tests
â”œâ”€â”€ uploads/                   # Temporary uploaded image storage
â”œâ”€â”€ qdrant_local/              # Local Qdrant storage (fallback)
â”œâ”€â”€ .env                       # Environment variables
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Qdrant** â€” vector database ([install guide](https://qdrant.tech/documentation/quick-start/))
- **Google Gemini API Key** â€” for LLM capabilities
- **CUDA (optional)** â€” for GPU-accelerated embeddings

### 1. Clone the Repository

```bash
git clone https://github.com/kirollos2001/Multimodal_Rag.git
cd Multimodal_Rag
```

### 2. Create Virtual Environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install fastapi uvicorn python-multipart jinja2
pip install google-generativeai
pip install torch transformers pillow
pip install qdrant-client
pip install python-dotenv
pip install sentencepiece protobuf
```

### 4. Configure Environment Variables

Create a `.env` file in the project root:

```env
# Gemini API
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL_NAME=gemini-3-flash-preview

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=products_siglip

# SigLIP Model
SIGLIP_MODEL_NAME=google/siglip-base-patch16-224

# Search
SEARCH_THRESHOLD=0.3
```

### 5. Start Qdrant

```bash
docker run -p 6333:6333 qdrant/qdrant
```

> **Note:** If Qdrant is not running, the system automatically falls back to local storage (`./qdrant_local`).

### 6. Ingest Product Data

Organize your product images in folders, each with an `info.txt`:

```
products_images/
â”œâ”€â”€ product_001/
â”‚   â”œâ”€â”€ info.txt         # Description: ..., ID: ..., Price: ...
â”‚   â”œâ”€â”€ front.jpg
â”‚   â””â”€â”€ side.jpg
â”œâ”€â”€ product_002/
â”‚   â”œâ”€â”€ info.txt
â”‚   â””â”€â”€ main.png
â””â”€â”€ ...
```

**`info.txt` format:**
```
Description: Black oversized hoodie with front pocket
ID: PROD-001
Price: 850
```

Run the ingestion pipeline:
```bash
python -m src.product_ingestion
```

### 7. Launch the App

```bash
uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```

Open your browser at **[http://localhost:8000](http://localhost:8000)** ğŸ‰

---

## ğŸ“¡ API Reference

### `GET /`
Serves the main chat UI.

### `POST /chat`
Main conversational endpoint â€” handles both chat and search.

| Parameter | Type | Description |
|-----------|------|-------------|
| `message` | `string` (form) | User's text message |
| `image_file` | `file` (form) | Optional image upload |
| `conversation_history` | `string` (form, JSON) | Optional chat history for context |

**Response:**
```json
{
  "reply": "Ù„Ù‚ÙŠØªÙ„Ùƒ Ø¬Ø§ÙƒØª Ø£Ø³ÙˆØ¯ Ø­Ù„Ùˆ Ù…Ù† Folder_X Ø¨Ø³Ø¹Ø± 1200 Ø¬Ù†ÙŠÙ‡ ğŸ”¥",
  "intent": "search",
  "products": [
    {
      "id": "PROD-001",
      "folder": "black_jacket_01",
      "price": 1200.0,
      "score": 0.8742,
      "description": "Black oversized jacket",
      "image": "front.jpg"
    }
  ],
  "extracted_params": {
    "keywords": "black jacket",
    "category": "jacket",
    "color": "black",
    "shape": null,
    "price_min": null,
    "price_max": 2000.0
  }
}
```

### `POST /search` *(legacy)*
Direct search endpoint without conversational AI.

| Parameter | Type | Description |
|-----------|------|-------------|
| `text_query` | `string` (form) | Search text |
| `image_file` | `file` (form) | Optional image upload |

---

## ğŸ§ª Testing

Run the end-to-end search flow test:

```bash
python tests/test_search_flow.py
```

This tests the full pipeline:
1. âœ… Qdrant connectivity
2. âœ… SigLIP embedding generation
3. âœ… Semantic search with price filtering
4. âœ… LLM parameter extraction
5. âœ… LLM natural language response generation

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Backend** | [FastAPI](https://fastapi.tiangolo.com/) |
| **LLM** | [Google Gemini](https://ai.google.dev/) (intent classification, param extraction, response generation) |
| **Embeddings** | [SigLIP](https://huggingface.co/google/siglip-base-patch16-224) (unified text-image encoder) |
| **Vector DB** | [Qdrant](https://qdrant.tech/) (cosine similarity search + metadata filtering) |
| **Frontend** | HTML, CSS, JavaScript + Jinja2 templates |
| **Deep Learning** | [PyTorch](https://pytorch.org/) + [HuggingFace Transformers](https://huggingface.co/docs/transformers) |

---

## ğŸ”‘ Key Design Decisions

- **SigLIP over CLIP** â€” SigLIP provides a shared embedding space for both text and images in a single model, enabling cross-modal search with a single vector collection.
- **Gemini for NLU** â€” Using Gemini for intent classification, parameter extraction, and response generation keeps the system flexible and multilingual without additional NLP pipelines.
- **Product Grouping** â€” Each product can have multiple vectors (text description + multiple images). Search results are grouped by product folder and merged to provide a complete result with all available metadata.
- **Arabic-First Support** â€” The system prompt and UI are designed for Arabic-speaking users, with automatic translation to English keywords for semantic embedding alignment.

---

## ğŸ“„ License

This project is for educational and personal use.

---

<p align="center">
  Made with â¤ï¸ and ğŸŒ
</p>
